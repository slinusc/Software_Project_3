{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "There are some POIs that are not in Switzerland. We will delete them from the database by using the following function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7f4372771364282"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(host=\"localhost\",port=27017)\n",
    "db = client[\"data_base_OSM\"]\n",
    "collection = db[\"bicycle_amenities\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T10:26:48.421384300Z",
     "start_time": "2023-11-18T10:26:48.393388800Z"
    }
   },
   "id": "bf90498cc361d74a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:55:15.160325500Z",
     "start_time": "2023-11-17T16:55:15.062810800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted documents with canton '['Baden-Württemberg', 'Vorarlberg', 'Trentino-Alto Adige/Südtirol', 'Lombardia', 'Auvergne-Rhône-Alpes', 'No canton found', 'Grand Est', 'Bourgogne-Franche-Comté', \"Valle d'Aosta / Vallée d'Aoste\"]'\n"
     ]
    }
   ],
   "source": [
    "wrong_POIs = [\"Baden-Württemberg\", \"Vorarlberg\", \"Trentino-Alto Adige/Südtirol\", \"Lombardia\", \"Auvergne-Rhône-Alpes\",\n",
    "              \"No canton found\", \"Grand Est\", \"Bourgogne-Franche-Comté\", \"Valle d'Aosta / Vallée d'Aoste\", \"Piemonte\"]\n",
    "\n",
    "\n",
    "def delete_wrong_POIs(wrong_POIs):\n",
    "    collection.delete_many({\"node.canton\": {\"$in\": wrong_POIs}})\n",
    "    print(f\"Deleted documents with canton '{wrong_POIs}'\")\n",
    "\n",
    "\n",
    "delete_wrong_POIs(wrong_POIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of documents with canton 'Baden-Württemberg': 0\n",
      "Count of documents with canton 'Vorarlberg': 0\n",
      "Count of documents with canton 'Trentino-Alto Adige/Südtirol': 0\n",
      "Count of documents with canton 'Lombardia': 0\n",
      "Count of documents with canton 'Auvergne-Rhône-Alpes': 0\n",
      "Count of documents with canton 'No canton found': 0\n",
      "Count of documents with canton 'Grand Est': 0\n",
      "Count of documents with canton 'Bourgogne-Franche-Comté': 0\n",
      "Count of documents with canton 'Valle d'Aosta / Vallée d'Aoste': 0\n"
     ]
    }
   ],
   "source": [
    "def check_wrong_POIs(wrong_POIs):\n",
    "    for wrong_POI in wrong_POIs:\n",
    "        count = collection.count_documents({\"node.canton\": {\"$in\": wrong_POIs}})\n",
    "        print(f\"Count of documents with canton '{wrong_POI}': {count}\")\n",
    "\n",
    "\n",
    "check_wrong_POIs(wrong_POIs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:55:19.720958Z",
     "start_time": "2023-11-17T16:55:19.396212500Z"
    }
   },
   "id": "567d585654851470"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cantons with french or italian names will be translated to german."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "574234028a628d35"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated documents with canton 'Vaud' to 'Waadt'\n",
      "Updated documents with canton 'Graubünden/Grischun/Grigioni' to 'Graubünden'\n",
      "Updated documents with canton 'Bern/Berne' to 'Bern'\n",
      "Updated documents with canton 'Valais/Wallis' to 'Wallis'\n",
      "Updated documents with canton 'Neuchâtel' to 'Neuenburg'\n",
      "Updated documents with canton 'Ticino' to 'Tessin'\n",
      "Updated documents with canton 'Genève' to 'Genf'\n",
      "Updated documents with canton 'Fribourg/Freiburg' to 'Freiburg'\n"
     ]
    }
   ],
   "source": [
    "canton_translation = {\n",
    "    \"Vaud\": \"Waadt\",\n",
    "    \"Graubünden/Grischun/Grigioni\": \"Graubünden\",\n",
    "    \"Bern/Berne\": \"Bern\",\n",
    "    \"Valais/Wallis\": \"Wallis\",\n",
    "    \"Neuchâtel\": \"Neuenburg\",\n",
    "    \"Ticino\": \"Tessin\",\n",
    "    \"Genève\": \"Genf\",\n",
    "    \"Fribourg/Freiburg\": \"Freiburg\"\n",
    "}\n",
    "\n",
    "\n",
    "def translate_canton(canton_translation):\n",
    "    for key, value in canton_translation.items():\n",
    "        collection.update_many({\"node.canton\": key}, {\"$set\": {\"node.canton\": value}})\n",
    "        print(f\"Updated documents with canton '{key}' to '{value}'\")\n",
    "\n",
    "\n",
    "translate_canton(canton_translation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T17:06:07.964012300Z",
     "start_time": "2023-11-17T17:06:07.346092800Z"
    }
   },
   "id": "900763e3ce556531"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of documents with canton 'Vaud': 0\n",
      "Count of documents with canton 'Graubünden/Grischun/Grigioni': 0\n",
      "Count of documents with canton 'Bern/Berne': 0\n",
      "Count of documents with canton 'Valais/Wallis': 0\n",
      "Count of documents with canton 'Neuchâtel': 0\n",
      "Count of documents with canton 'Ticino': 0\n",
      "Count of documents with canton 'Genève': 0\n",
      "Count of documents with canton 'Fribourg/Freiburg': 0\n"
     ]
    }
   ],
   "source": [
    "def check_canton_translation(canton_translation):\n",
    "    for key, value in canton_translation.items():\n",
    "        count = collection.count_documents({\"node.canton\": key})\n",
    "        print(f\"Count of documents with canton '{key}': {count}\")\n",
    "\n",
    "\n",
    "check_canton_translation(canton_translation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T09:28:59.764513300Z",
     "start_time": "2023-11-18T09:28:59.391828700Z"
    }
   },
   "id": "5549d9924d65b24a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Enrichment of the data with pump stations in the city of Zurich."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8e5d6bbce408fa2"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': {'amenity': 'compressed_air', 'id': '1011', 'lat': '47.3917066531', 'lon': '8.5185306277', 'canton': 'Zürich', 'location': {'type': 'Point', 'coordinates': [8.5185306277, 47.3917066531]}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open(\"../data/taz.velopumpstationen_p.json\", \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "def transform_feature(feature):\n",
    "    # Extrahiert und transformiert ein einzelnes Feature\n",
    "    transformed = {\n",
    "        \"amenity\": \"compressed_air\",\n",
    "        \"id\": str(feature[\"properties\"][\"id1\"]),\n",
    "        \"lat\": str(feature[\"geometry\"][\"coordinates\"][1]),\n",
    "        \"lon\": str(feature[\"geometry\"][\"coordinates\"][0]),\n",
    "        \"canton\": \"Zürich\",\n",
    "        \"location\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": feature[\"geometry\"][\"coordinates\"]\n",
    "        }\n",
    "    }\n",
    "    return {\"node\": transformed}\n",
    "\n",
    "def transform_json(input_data):\n",
    "    # Transformiert die gesamte FeatureCollection\n",
    "    transformed_features = [transform_feature(feature) for feature in input_data[\"features\"]]\n",
    "    return transformed_features\n",
    "\n",
    "# Transformation durchführen\n",
    "transformed_json = transform_json(data)\n",
    "\n",
    "print(transformed_json[0])\n",
    "\n",
    "json.dump(transformed_json, open(\"../data/compressed_air_transformed.json\", \"w\", encoding=\"utf-8\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T10:26:04.495008500Z",
     "start_time": "2023-11-18T10:26:04.465728100Z"
    }
   },
   "id": "c73eaefd8edb48a8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted documents into database\n"
     ]
    }
   ],
   "source": [
    "def load_data_in_db(data):\n",
    "    collection.insert_many(data)\n",
    "    print(\"Inserted documents into database\")\n",
    "    \n",
    "load_data_in_db(transformed_json)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T10:26:53.530921400Z",
     "start_time": "2023-11-18T10:26:53.496491100Z"
    }
   },
   "id": "f5a9b48c93c5d6b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
